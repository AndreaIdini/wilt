<!DOCTYPE html>
<html lang="en">
<head>
  
    <title>The semantic of Machine Learning :: WILT</title>
  
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="Today I learned again that most things in life are a matter of semantics&amp;hellip; After some online lectures in Machine Learning techniques I discovered that what I call &amp;ldquo;Ordinary Least Squares&amp;rdquo; is generalized as a &amp;ldquo;cost function&amp;rdquo; and a simplified version of the &amp;ldquo;Newton Method&amp;rdquo; is refferred to as &amp;ldquo;Gradient Descent&amp;rdquo;.
So, basically, the core of a supervised learned algorithm seems to be the choose of an appropriate &amp;ldquo;cost function&amp;rdquo; and the application of the most effective minimization algorithm." />
<meta name="keywords" content="" />
<meta name="robots" content="noodp" />
<link rel="canonical" href="http://andreaidini.github.io/wilt/2014/03/23/the-semantic-of-machine-learning/" />




<link rel="stylesheet" href="http://andreaidini.github.io/wilt/assets/style.css">

  <link rel="stylesheet" href="http://andreaidini.github.io/wilt/assets/green.css">






<link rel="apple-touch-icon" href="http://andreaidini.github.io/wilt/img/apple-touch-icon-192x192.png">

  <link rel="shortcut icon" href="http://andreaidini.github.io/wilt/">



<meta name="twitter:card" content="summary" />



<meta property="og:locale" content="en" />
<meta property="og:type" content="article" />
<meta property="og:title" content="The semantic of Machine Learning">
<meta property="og:description" content="Today I learned again that most things in life are a matter of semantics&amp;hellip; After some online lectures in Machine Learning techniques I discovered that what I call &amp;ldquo;Ordinary Least Squares&amp;rdquo; is generalized as a &amp;ldquo;cost function&amp;rdquo; and a simplified version of the &amp;ldquo;Newton Method&amp;rdquo; is refferred to as &amp;ldquo;Gradient Descent&amp;rdquo;.
So, basically, the core of a supervised learned algorithm seems to be the choose of an appropriate &amp;ldquo;cost function&amp;rdquo; and the application of the most effective minimization algorithm." />
<meta property="og:url" content="http://andreaidini.github.io/wilt/2014/03/23/the-semantic-of-machine-learning/" />
<meta property="og:site_name" content="WILT" />

  
    <meta property="og:image" content="http://andreaidini.github.io/wilt/">
  

<meta property="og:image:width" content="2048">
<meta property="og:image:height" content="1024">

  <meta property="article:section" content="Coding" />


  <meta property="article:published_time" content="2014-03-22 23:38:47 &#43;0000 &#43;0000" />












</head>
<body class="green">


<div class="container center headings--one-size">

  <header class="header">
  <div class="header__inner">
    <div class="header__logo">
      <a href="http://andreaidini.github.io/wilt/">
  <div class="logo">
    Terminal
  </div>
</a>

    </div>
    
  </div>
  
</header>


  <div class="content">
    
<div class="post">
  <h1 class="post-title">
    <a href="http://andreaidini.github.io/wilt/2014/03/23/the-semantic-of-machine-learning/">The semantic of Machine Learning</a></h1>
  <div class="post-meta">
    
      <span class="post-date">
        2014-03-22 
      </span>
    
    
    <span class="post-author">:: Andrea Idini</span>
    
  </div>

  
  <span class="post-tags">
    
    #<a href="http://andreaidini.github.io/wilt/tags/machine-learning/">machine learning</a>&nbsp;
    
  </span>
  

  

  

  <div class="post-content"><div>
        <p>Today I learned again that most things in life are a matter of semantics&hellip; After some online lectures in Machine Learning techniques I discovered that what I call <em>&ldquo;Ordinary Least Squares&rdquo;</em> is generalized as a &ldquo;<em>cost function</em>&rdquo; and a simplified version of the <em>&ldquo;Newton Method&rdquo;</em> is refferred to as <em>&ldquo;Gradient Descent&rdquo;.</em></p>
<p>So, basically, the core of a supervised learned algorithm seems to be the choose of an appropriate <em>&ldquo;cost function&rdquo;</em> and the application of the most effective minimization algorithm.</p>

      </div></div>

  
  
<div class="pagination">
    <div class="pagination__title">
        <span class="pagination__title-h"></span>
        <hr />
    </div>
    <div class="pagination__buttons">
        
        <span class="button previous">
            <a href="http://andreaidini.github.io/wilt/2014/03/25/the-power-of-dns/">
                <span class="button__icon">←</span>
                <span class="button__text">The website craft 101</span>
            </a>
        </span>
        
        
        <span class="button next">
            <a href="http://andreaidini.github.io/wilt/2014/03/18/how-to-see-space-occupied-by-directories-in-linux-terminal/">
                <span class="button__text">How to see space occupied by directories in Linux Terminal</span>
                <span class="button__icon">→</span>
            </a>
        </span>
        
    </div>
</div>

  

  

</div>

  </div>

  
    <footer class="footer">
  <div class="footer__inner">
    
      <div class="copyright">
        <span>© 2021 Powered by <a href="http://gohugo.io">Hugo</a></span>
    
        <span>:: Theme made by <a href="https://twitter.com/panr">panr</a></span>
      </div>
  </div>
</footer>

<script src="http://andreaidini.github.io/wilt/assets/main.js"></script>
<script src="http://andreaidini.github.io/wilt/assets/prism.js"></script>







  
</div>

</body>
</html>
